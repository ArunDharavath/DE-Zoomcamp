{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c1d0c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "import pandas as pd\n",
    "from pyspark.sql import types\n",
    "from pyspark.conf import SparkConf\n",
    "from pyspark.context import SparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a248f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName('test') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84c6c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "green_schema = types.StructType([\n",
    "    types.StructField(\"VendorID\", types.IntegerType(), True),\n",
    "    types.StructField(\"lpep_pickup_datetime\", types.TimestampType(), True),\n",
    "    types.StructField(\"lpep_dropoff_datetime\", types.TimestampType(), True),\n",
    "    types.StructField(\"store_and_fwd_flag\", types.StringType(), True),\n",
    "    types.StructField(\"RatecodeID\", types.IntegerType(), True),\n",
    "    types.StructField(\"PULocationID\", types.IntegerType(), True),\n",
    "    types.StructField(\"DOLocationID\", types.IntegerType(), True),\n",
    "    types.StructField(\"passenger_count\", types.IntegerType(), True),\n",
    "    types.StructField(\"trip_distance\", types.DoubleType(), True),\n",
    "    types.StructField(\"fare_amount\", types.DoubleType(), True),\n",
    "    types.StructField(\"extra\", types.DoubleType(), True),\n",
    "    types.StructField(\"mta_tax\", types.DoubleType(), True),\n",
    "    types.StructField(\"tip_amount\", types.DoubleType(), True),\n",
    "    types.StructField(\"tolls_amount\", types.DoubleType(), True),\n",
    "    types.StructField(\"ehail_fee\", types.DoubleType(), True),\n",
    "    types.StructField(\"improvement_surcharge\", types.DoubleType(), True),\n",
    "    types.StructField(\"total_amount\", types.DoubleType(), True),\n",
    "    types.StructField(\"payment_type\", types.IntegerType(), True),\n",
    "    types.StructField(\"trip_type\", types.IntegerType(), True),\n",
    "    types.StructField(\"congestion_surcharge\", types.DoubleType(), True)\n",
    "])\n",
    "\n",
    "yellow_schema = types.StructType([\n",
    "    types.StructField(\"VendorID\", types.IntegerType(), True),\n",
    "    types.StructField(\"tpep_pickup_datetime\", types.TimestampType(), True),\n",
    "    types.StructField(\"tpep_dropoff_datetime\", types.TimestampType(), True),\n",
    "    types.StructField(\"passenger_count\", types.IntegerType(), True),\n",
    "    types.StructField(\"trip_distance\", types.DoubleType(), True),\n",
    "    types.StructField(\"RatecodeID\", types.IntegerType(), True),\n",
    "    types.StructField(\"store_and_fwd_flag\", types.StringType(), True),\n",
    "    types.StructField(\"PULocationID\", types.IntegerType(), True),\n",
    "    types.StructField(\"DOLocationID\", types.IntegerType(), True),\n",
    "    types.StructField(\"payment_type\", types.IntegerType(), True),\n",
    "    types.StructField(\"fare_amount\", types.DoubleType(), True),\n",
    "    types.StructField(\"extra\", types.DoubleType(), True),\n",
    "    types.StructField(\"mta_tax\", types.DoubleType(), True),\n",
    "    types.StructField(\"tip_amount\", types.DoubleType(), True),\n",
    "    types.StructField(\"tolls_amount\", types.DoubleType(), True),\n",
    "    types.StructField(\"improvement_surcharge\", types.DoubleType(), True),\n",
    "    types.StructField(\"total_amount\", types.DoubleType(), True),\n",
    "    types.StructField(\"congestion_surcharge\", types.DoubleType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7e0cb9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "year = 2020\n",
    "\n",
    "for month in range(1, 13):\n",
    "    print(f'processing data for {year}/{month}')\n",
    "\n",
    "    input_path = f'data/raw/green/{year}/{month:02d}/'\n",
    "    output_path = f'data/pq/green/{year}/{month:02d}/'\n",
    "\n",
    "    df_green = spark.read \\\n",
    "        .option(\"header\", \"true\") \\\n",
    "        .schema(green_schema) \\\n",
    "        .csv(input_path)\n",
    "\n",
    "    df_green \\\n",
    "        .repartition(4) \\\n",
    "        .write.parquet(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dade599f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ac2ad7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "year = 2021 \n",
    "\n",
    "for month in range(1, 8):\n",
    "    print(f'processing data for {year}/{month}')\n",
    "\n",
    "    input_path = f'data/raw/green/{year}/{month:02d}/'\n",
    "    output_path = f'data/pq/green/{year}/{month:02d}/'\n",
    "\n",
    "    df_green = spark.read \\\n",
    "        .option(\"header\", \"true\") \\\n",
    "        .schema(green_schema) \\\n",
    "        .csv(input_path)\n",
    "\n",
    "    df_green \\\n",
    "        .repartition(4) \\\n",
    "        .write.parquet(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff4265d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19326bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2020\n",
    "\n",
    "for month in range(1, 13):\n",
    "    print(f'processing data for {year}/{month}')\n",
    "\n",
    "    input_path = f'data/raw/yellow/{year}/{month:02d}/'\n",
    "    output_path = f'data/pq/yellow/{year}/{month:02d}/'\n",
    "\n",
    "    df_yellow = spark.read \\\n",
    "        .option(\"header\", \"true\") \\\n",
    "        .schema(yellow_schema) \\\n",
    "        .csv(input_path)\n",
    "\n",
    "    df_yellow \\\n",
    "        .repartition(4) \\\n",
    "        .write.parquet(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeca811a",
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2021\n",
    "\n",
    "for month in range(1, 8):\n",
    "    print(f'processing data for {year}/{month}')\n",
    "\n",
    "    input_path = f'data/raw/yellow/{year}/{month:02d}/'\n",
    "    output_path = f'data/pq/yellow/{year}/{month:02d}/'\n",
    "\n",
    "    df_yellow = spark.read \\\n",
    "        .option(\"header\", \"true\") \\\n",
    "        .schema(yellow_schema) \\\n",
    "        .csv(input_path)\n",
    "\n",
    "    df_yellow \\\n",
    "        .repartition(4) \\\n",
    "        .write.parquet(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a855cfda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_green = spark.read.parquet('data/pq/green/*/*')\n",
    "df_yellow = spark.read.parquet('data/pq/yellow/*/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000e1432",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_green = df_green \\\n",
    "    .withColumnRenamed('lpep_pickup_datetime', 'pickup_datetime') \\\n",
    "    .withColumnRenamed('lpep_dropoff_datetime', 'dropoff_datetime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e20ebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+-------------------+------------------+----------+------------+------------+---------------+-------------+-----------+-----+-------+----------+------------+---------+---------------------+------------+------------+---------+--------------------+\n",
      "|VendorID|    pickup_datetime|   dropoff_datetime|store_and_fwd_flag|RatecodeID|PULocationID|DOLocationID|passenger_count|trip_distance|fare_amount|extra|mta_tax|tip_amount|tolls_amount|ehail_fee|improvement_surcharge|total_amount|payment_type|trip_type|congestion_surcharge|\n",
      "+--------+-------------------+-------------------+------------------+----------+------------+------------+---------------+-------------+-----------+-----+-------+----------+------------+---------+---------------------+------------+------------+---------+--------------------+\n",
      "|       2|2020-01-22 16:17:49|2020-01-22 16:41:43|                 N|         1|          25|         125|              1|         3.69|       17.5|  1.0|    0.5|      4.41|         0.0|     NULL|                  0.3|       26.46|           1|        1|                2.75|\n",
      "|    NULL|2020-01-29 13:59:00|2020-01-29 14:25:00|              NULL|      NULL|         223|          73|           NULL|         7.36|       30.3| 2.75|    0.5|       0.0|         0.0|     NULL|                  0.3|       33.85|        NULL|     NULL|                NULL|\n",
      "|       2|2020-01-09 21:09:23|2020-01-09 21:22:48|                 N|         1|          33|         181|              1|         2.06|       10.5|  0.5|    0.5|       0.0|         0.0|     NULL|                  0.3|        11.8|           2|        1|                 0.0|\n",
      "|    NULL|2020-01-02 12:20:00|2020-01-02 12:59:00|              NULL|      NULL|          26|          35|           NULL|         5.73|      34.13| 2.75|    0.5|       0.0|         0.0|     NULL|                  0.3|       37.68|        NULL|     NULL|                NULL|\n",
      "|       2|2020-01-15 15:17:00|2020-01-15 15:24:43|                 N|         1|          41|         152|              1|         0.94|        7.0|  0.0|    0.5|       0.0|         0.0|     NULL|                  0.3|         7.8|           2|        1|                 0.0|\n",
      "|       1|2020-01-26 17:06:29|2020-01-26 17:11:13|                 N|         1|         116|         152|              1|          1.0|        5.5|  1.0|    0.5|       0.0|         0.0|     NULL|                  0.3|         7.3|           2|        1|                 0.0|\n",
      "|       2|2020-01-16 00:37:59|2020-01-16 00:40:48|                 N|         1|           7|           7|              1|         0.54|       -4.0| -0.5|   -0.5|       0.0|         0.0|     NULL|                 -0.3|        -5.3|           3|        1|                 0.0|\n",
      "|       1|2020-01-02 12:07:43|2020-01-02 12:15:51|                 N|         1|          42|         116|              1|          1.4|        7.5|  0.0|    0.5|       0.0|         0.0|     NULL|                  0.3|         8.3|           2|        1|                 0.0|\n",
      "|       2|2020-01-25 19:11:38|2020-01-25 19:21:19|                 N|         1|          92|          82|              1|         4.06|       13.5|  0.0|    0.5|       0.0|         0.0|     NULL|                  0.3|        14.3|           2|        1|                 0.0|\n",
      "|       2|2020-01-02 16:30:32|2020-01-02 16:42:57|                 N|         1|          97|          49|              1|         1.56|        9.5|  1.0|    0.5|       2.0|         0.0|     NULL|                  0.3|        13.3|           1|        1|                 0.0|\n",
      "+--------+-------------------+-------------------+------------------+----------+------------+------------+---------------+-------------+-----------+-----+-------+----------+------------+---------+---------------------+------------+------------+---------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_green.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d11287",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yellow = df_yellow \\\n",
    "    .withColumnRenamed('tpep_pickup_datetime', 'pickup_datetime') \\\n",
    "    .withColumnRenamed('tpep_dropoff_datetime', 'dropoff_datetime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f14f282",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_cols = []\n",
    "\n",
    "yellow_cols = set(df_yellow.columns)\n",
    "\n",
    "for col in df_green.columns:\n",
    "    if col in yellow_cols:\n",
    "        common_cols.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f6dbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "df_green_sel = df_green \\\n",
    "    .select(common_cols) \\\n",
    "    .withColumn('service_type', F.lit('green'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d694d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yellow_sel = df_yellow \\\n",
    "    .select(common_cols) \\\n",
    "    .withColumn('service_type', F.lit('yellow'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da30bd1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trips_data = df_green_sel.unionAll(df_yellow_sel)\n",
    "df_trips_data.groupBy('service_type').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e6930d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trips_data.registerTempTable('trips_data')\n",
    "spark.sql(\"\"\"\n",
    "SELECT\n",
    "    service_type,\n",
    "    count(1)\n",
    "FROM\n",
    "    trips_data\n",
    "GROUP BY \n",
    "    service_type\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c816fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = spark.sql(\"\"\"\n",
    "SELECT \n",
    "    -- Revenue grouping \n",
    "    PULocationID AS revenue_zone,\n",
    "    date_trunc('month', pickup_datetime) AS revenue_month, \n",
    "    service_type, \n",
    "\n",
    "    -- Revenue calculation \n",
    "    SUM(fare_amount) AS revenue_monthly_fare,\n",
    "    SUM(extra) AS revenue_monthly_extra,\n",
    "    SUM(mta_tax) AS revenue_monthly_mta_tax,\n",
    "    SUM(tip_amount) AS revenue_monthly_tip_amount,\n",
    "    SUM(tolls_amount) AS revenue_monthly_tolls_amount,\n",
    "    SUM(improvement_surcharge) AS revenue_monthly_improvement_surcharge,\n",
    "    SUM(total_amount) AS revenue_monthly_total_amount,\n",
    "    SUM(congestion_surcharge) AS revenue_monthly_congestion_surcharge,\n",
    "\n",
    "    -- Additional calculations\n",
    "    AVG(passenger_count) AS avg_montly_passenger_count,\n",
    "    AVG(trip_distance) AS avg_montly_trip_distance\n",
    "FROM\n",
    "    trips_data\n",
    "GROUP BY\n",
    "    1, 2, 3\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f686997",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result.coalesce(1).write.parquet('data/report/revenue/', mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64623709",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd18a81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pyspark/sql/dataframe.py:329: FutureWarning: Deprecated in 2.0, use createOrReplaceTempView instead.\n",
      "  warnings.warn(\"Deprecated in 2.0, use createOrReplaceTempView instead.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "df_green.registerTempTable('green')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7cf3c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['VendorID',\n",
       " 'pickup_datetime',\n",
       " 'dropoff_datetime',\n",
       " 'store_and_fwd_flag',\n",
       " 'RatecodeID',\n",
       " 'PULocationID',\n",
       " 'DOLocationID',\n",
       " 'passenger_count',\n",
       " 'trip_distance',\n",
       " 'fare_amount',\n",
       " 'extra',\n",
       " 'mta_tax',\n",
       " 'tip_amount',\n",
       " 'tolls_amount',\n",
       " 'ehail_fee',\n",
       " 'improvement_surcharge',\n",
       " 'total_amount',\n",
       " 'payment_type',\n",
       " 'trip_type',\n",
       " 'congestion_surcharge']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_green.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3a0b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_green_revenue = spark.sql(\"\"\"\n",
    "SELECT \n",
    "    date_trunc('hour', pickup_datetime) AS hour, \n",
    "    PULocationID AS zone,\n",
    "\n",
    "    SUM(total_amount) AS amount,\n",
    "    COUNT(1) AS number_records\n",
    "FROM\n",
    "    green\n",
    "WHERE\n",
    "    pickup_datetime >= '2020-01-01 00:00:00'\n",
    "GROUP BY\n",
    "    1, 2\n",
    "ORDER BY\n",
    "    1, 2\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0848bb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/02/28 10:25:00 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "25/02/28 10:25:00 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_green_revenue \\\n",
    "    .repartition(20) \\\n",
    "    .write.parquet('data/report/revenue/green', mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de886f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yellow.registerTempTable('yellow')\n",
    "\n",
    "\n",
    "df_yellow_revenue = spark.sql(\"\"\"\n",
    "SELECT \n",
    "    date_trunc('hour', pickup_datetime) AS hour, \n",
    "    PULocationID AS zone,\n",
    "\n",
    "    SUM(total_amount) AS amount,\n",
    "    COUNT(1) AS number_records\n",
    "FROM\n",
    "    yellow\n",
    "WHERE\n",
    "    pickup_datetime >= '2020-01-01 00:00:00'\n",
    "GROUP BY\n",
    "    1, 2\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d345c1d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/02/28 10:25:34 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "25/02/28 10:25:35 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_yellow_revenue \\\n",
    "    .repartition(20) \\\n",
    "    .write.parquet('data/report/revenue/yellow', mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68c4a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_green_revenue_tmp = df_green_revenue \\\n",
    "    .withColumnRenamed('amount', 'green_amount') \\\n",
    "    .withColumnRenamed('number_records', 'green_number_records')\n",
    "\n",
    "df_yellow_revenue_tmp = df_yellow_revenue \\\n",
    "    .withColumnRenamed('amount', 'yellow_amount') \\\n",
    "    .withColumnRenamed('number_records', 'yellow_number_records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b535d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_join = df_green_revenue_tmp.join(df_yellow_revenue_tmp, on=['hour', 'zone'], how='outer')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c06b15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/02/28 11:13:37 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_join.write.parquet('data/report/revenue/total', mode='overwrite')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcbb1872",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_join = spark.read.parquet('data/report/revenue/total')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20ac2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zones = spark.read.parquet('zones/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a3000b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = df_join.join(df_zones, df_join.zone == df_zones.LocationID)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7862d6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hour',\n",
       " 'zone',\n",
       " 'green_amount',\n",
       " 'green_number_records',\n",
       " 'yellow_amount',\n",
       " 'yellow_number_records',\n",
       " 'LocationID',\n",
       " 'Borough',\n",
       " 'Zone',\n",
       " 'service_zone']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a68d10f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----+------------------+--------------------+------------------+---------------------+----------+---------+--------------------+------------+\n",
      "|               hour|zone|      green_amount|green_number_records|     yellow_amount|yellow_number_records|LocationID|  Borough|                Zone|service_zone|\n",
      "+-------------------+----+------------------+--------------------+------------------+---------------------+----------+---------+--------------------+------------+\n",
      "|2020-01-01 00:00:00|  22|              15.8|                   1|              NULL|                 NULL|        22| Brooklyn|    Bensonhurst West|   Boro Zone|\n",
      "|2020-01-01 00:00:00|  32| 68.94999999999999|                   2|              18.0|                    1|        32|    Bronx|           Bronxdale|   Boro Zone|\n",
      "|2020-01-01 00:00:00|  45|              NULL|                NULL| 732.4800000000002|                   42|        45|Manhattan|           Chinatown| Yellow Zone|\n",
      "|2020-01-01 00:00:00|  47|              13.3|                   1|               8.3|                    1|        47|    Bronx|  Claremont/Bathgate|   Boro Zone|\n",
      "|2020-01-01 00:00:00|  66|386.75000000000006|                  18|260.54999999999995|                   10|        66| Brooklyn|  DUMBO/Vinegar Hill|   Boro Zone|\n",
      "|2020-01-01 00:00:00|  82| 305.1200000000001|                  28|              29.8|                    1|        82|   Queens|            Elmhurst|   Boro Zone|\n",
      "|2020-01-01 00:00:00| 113|              NULL|                NULL| 3984.319999999998|                  220|       113|Manhattan|Greenwich Village...| Yellow Zone|\n",
      "|2020-01-01 00:00:00| 143|             55.95|                   2| 2142.059999999999|                  128|       143|Manhattan| Lincoln Square West| Yellow Zone|\n",
      "|2020-01-01 00:00:00| 146|             99.37|                   6|110.74000000000001|                    7|       146|   Queens|Long Island City/...|   Boro Zone|\n",
      "|2020-01-01 00:00:00| 165|             66.14|                   2|              NULL|                 NULL|       165| Brooklyn|             Midwood|   Boro Zone|\n",
      "+-------------------+----+------------------+--------------------+------------------+---------------------+----------+---------+--------------------+------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_result.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e7866e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/02/28 11:39:07 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_result.drop('LocationID', 'zone').write.parquet('tmp/revenue-zones')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66f2244",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2012abf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "credentials_location = '/Users/arundharavath/Downloads/Projects/DE_Zcp/dez_kestra_google_credentials.json'\n",
    "\n",
    "conf = SparkConf() \\\n",
    "    .setMaster('local[*]') \\\n",
    "    .setAppName('test') \\\n",
    "    .set(\"spark.jars\", \"./lib/gcs-connector-hadoop3-2.2.5.jar\") \\\n",
    "    .set(\"spark.hadoop.google.cloud.auth.service.account.enable\", \"true\") \\\n",
    "    .set(\"spark.hadoop.google.cloud.auth.service.account.json.keyfile\", credentials_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec39ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext(conf=conf)\n",
    "\n",
    "hadoop_conf = sc._jsc.hadoopConfiguration()\n",
    "\n",
    "hadoop_conf.set(\"fs.AbstractFileSystem.gs.impl\",  \"com.google.cloud.hadoop.fs.gcs.GoogleHadoopFS\")\n",
    "hadoop_conf.set(\"fs.gs.impl\", \"com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystem\")\n",
    "hadoop_conf.set(\"fs.gs.auth.service.account.json.keyfile\", credentials_location)\n",
    "hadoop_conf.set(\"fs.gs.auth.service.account.enable\", \"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1157538e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .config(conf=sc.getConf()) \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d0ec98c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_green = spark.read.parquet('gs://dez_nytaxi_data/pq/green/*/*')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce3cd79",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
